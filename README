We start with client_secrets.json, trainRaw.csv, and testRaw.csv, we run 

python preprocess.py

To generate train.csv test.csv groundTruth.csv



After generating the client_secrets.json and placing it in the directory, we run the following line to call on the Prediction API

python gpredictions.py whateveryourbucketis/trainingsetname.csv modelname projectid apiCall

which writes to results.csv and is written in such as way as to record even when quota is met during runtime
the folllowing is accepted for apiCall (in retrospect maybe better implemented as a flag):
	list		lists all models trained
	train		trains using the csv given, giving it name modelname under project projectid
	describe	description of the specified trained model
	predict		predict on dataset in test.csv
	delete		delete specified model
	everything	list, train, describe, predict, then delete



And after results are recorded, we run

python visualize.py

to get time plotted against ground truth in blue and predictions in green
To look at different predictions, change the preprocessing step in preprocess.py, line 36
